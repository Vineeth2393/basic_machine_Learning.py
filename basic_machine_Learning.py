# Check the versions of libraries # Python versionimport sysprint('Python: {}'.format(sys.version))# scipyimport scipyprint('scipy: {}'.format(scipy.__version__))# numpyimport numpyprint('numpy: {}'.format(numpy.__version__))# matplotlibimport matplotlibprint('matplotlib: {}'.format(matplotlib.__version__))# pandasimport pandas as pdprint('pandas: {}'.format(pd.__version__))# scikit-learnimport sklearnprint('sklearn: {}'.format(sklearn.__version__))# Load librariesfrom pandas.plotting import scatter_matrixfrom matplotlib import pyplot as pltfrom sklearn.model_selection import train_test_splitfrom sklearn.model_selection import cross_val_scorefrom sklearn.model_selection import StratifiedKFoldfrom sklearn.metrics import classification_reportfrom sklearn.metrics import confusion_matrixfrom sklearn.metrics import accuracy_scorefrom sklearn.linear_model import LogisticRegressionfrom sklearn.tree import DecisionTreeClassifierfrom sklearn.neighbors import KNeighborsClassifierfrom sklearn.discriminant_analysis import LinearDiscriminantAnalysisfrom sklearn.naive_bayes import GaussianNBfrom sklearn.svm import SVC################################################################### Load dataseturl = ("https://raw.githubusercontent.com/jbrownlee/Datasets/master/iris.csv")name  = ['sepal-length','sepal-width','petal-lenght','petal-wdith','class']df = pd.read_csv(url,names = name)#Summarise the dataset"""1.Summarise the dataset2.Peek at the data itself3.Statistical summary of all attributes4.Breakdown of the data by class variable"""#Dimension of the dataset#shapeprint(df.shape)#Peek of the data print(df.head(10))#Statiscal summary or descriptionprint(df.describe())#Class distributionprint(df.groupby('class').size())#or you can use print(df['class'].value_counts())#Visulization #univarite plotsdf.plot(kind='box',subplots=True, layout=(2,2),        sharex = False ,sharey = False)plt.show()#histogram df.hist()plt.show()#mulivarirte Plots #scatter plot scatter_matrix(df)plt.show()# Split-out validation datasetarray = df.valuesX = array[:,0:4]y = array[:,4]X_train, X_validation, Y_train, Y_validation = train_test_split(X, y, test_size=0.20, random_state=1, shuffle=True)#Test Harness""" We will use strafied 10-fold cross validationdata will be split into 10 parts , 9 on train and one test """#Building Model# Spot Check Algorithmsmodels = []models.append(('LR', LogisticRegression(solver='liblinear', multi_class='ovr')))models.append(('LDA', LinearDiscriminantAnalysis()))models.append(('KNN', KNeighborsClassifier()))models.append(('CART', DecisionTreeClassifier()))models.append(('NB', GaussianNB()))models.append(('SVM', SVC(gamma='auto')))# evaluate each model in turnresults = []names = []for name, model in models:	kfold = StratifiedKFold(n_splits=10, random_state=1, shuffle=True)	cv_results = cross_val_score(model, X_train, Y_train, cv=kfold, scoring='accuracy')	results.append(cv_results)	names.append(name)	print('%s: %f (%f)' % (name, cv_results.mean(), cv_results.std()))#Compare alogortim using Visulizationplt.boxplot(results, labels=names)plt.title('Algorithm Comparison')plt.show()# Make predictions on validation datasetmodel = SVC(gamma='auto')model.fit(X_train, Y_train)predictions = model.predict(X_validation)# Evaluate predictionsprint(accuracy_score(Y_validation, predictions))print(confusion_matrix(Y_validation, predictions))print(classification_report(Y_validation, predictions))